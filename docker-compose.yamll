# SPARK network diagram https://www.ibm.com/docs/en/izoda/1.1.0?topic=spark-configuring-networking-apache

version: '3.9'
services:
  master-node:
    image: hadooptest
    build: .
    hostname: master-node # docker run
    ports:
      - "7077:7077"
      - "8080:8080"
      - "9000:9000"
      - "9870:9870"
      - "4040-4050:4040-4050"
    # README: Use this if starting NameNode for the first time
    command: bash -c "./hadoop-3.3.4/bin/hdfs namenode -format && ./hadoop-3.3.4/bin/hdfs --daemon start namenode && jps && sleep 999999d"
    # && ./hadoop-3.3.4/bin/hdfs --daemon start datanode 
    # README: Use this if HDFS is present
    # command: bash -c "./hadoop-3.3.4/bin/hdfs --daemon start namenode && jps && sleep 999999d"
    # command: bash -c "./hadoop-3.3.4/bin/hdfs namenode -format && ./hadoop-3.3.4/bin/hdfs --daemon start namenode && ./hadoop-3.3.4/bin/hdfs --daemon start datanode && $$SPARK_HOME/sbin/start-master.sh && $$SPARK_HOME/sbin/start-worker.sh spark://master-node:7077"
    networks:
      - spark-network # docker network create + docker run
    volumes:
      - hdfs-volume:/hdfs-data # docker run

networks:
  spark-network: {}

volumes:
  hdfs-volume: # docker run
